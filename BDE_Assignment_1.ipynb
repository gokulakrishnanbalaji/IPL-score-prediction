{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMVCwDTEgT6h8M0MLQqg36p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gokulakrishnanbalaji/IPL-score-prediction/blob/main/BDE_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Name: Gokulakrishnan B\n",
        "# Roll No: 205002032\n",
        "# Sub: Big Data Engineering"
      ],
      "metadata": {
        "id": "H_NtZAco2Suq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSk3vIOnojyP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset can be dowloaded from https://drive.google.com/file/d/1Yp0t8S5sn0pvNTD37BcHHvSIylrnpj5X/view?usp=sharing"
      ],
      "metadata": {
        "id": "QxVsRDa23IRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/BATTING STATS - IPL_2022.csv')"
      ],
      "metadata": {
        "id": "o4TxiOC2o9-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "CsWSzrTypFMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "wx5oprVppGkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# There are 14 features and 162 data points in the dataset"
      ],
      "metadata": {
        "id": "Kz27lx2_pNRO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's check for missing values"
      ],
      "metadata": {
        "id": "qHrBOvyxqH_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().sum()"
      ],
      "metadata": {
        "id": "2T6krnqrqDgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are no missing values"
      ],
      "metadata": {
        "id": "0zL4lO6MqchF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets understand what each column/feature mean?"
      ],
      "metadata": {
        "id": "K-YMmWcqqZ48"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "D5BFU_xPqloc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "r0LFwAT4voaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Convert HS and Avg to Float"
      ],
      "metadata": {
        "id": "koZyz5jBv1gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['HS'] = df['HS'].str.replace('*', '')\n",
        "df['Avg'] = df['Avg'].str.replace('-', '0')"
      ],
      "metadata": {
        "id": "54cBk44xxgh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['HS'] = df['HS'].astype(float)\n",
        "df['Avg'] = df['Avg'].astype(float)"
      ],
      "metadata": {
        "id": "zi8Bwj3QxC_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "metadata": {
        "id": "yW5_ezZ9qrDi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## There are no categorical features, the numerical features (except name) need to be scaled(inference)"
      ],
      "metadata": {
        "id": "5IVa1e7AqtH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.POS.unique()"
      ],
      "metadata": {
        "id": "n3lTSWFmrBEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The POS column is the ranking and they are unique. We could remove them as they don't have any numerical significance, but we might loss the inverse relationship between rating and runs. But for time being lets ignore the POS feature"
      ],
      "metadata": {
        "id": "KmbH_0OvrHwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['POS'],axis=1)"
      ],
      "metadata": {
        "id": "IbXluJasrvnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since name column has nothing to do with the runs scored we'll remove them."
      ],
      "metadata": {
        "id": "BQ2rMMBTuHZu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df=df.drop(['Player'],axis=1)"
      ],
      "metadata": {
        "id": "E9VcVgShuNcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "gElKmRZFr_v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets split the dataset into X and y"
      ],
      "metadata": {
        "id": "IlYqxHMosJcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.loc[:, df.columns != 'Runs']\n",
        "y=df.loc[:, df.columns == 'Runs']"
      ],
      "metadata": {
        "id": "Jc8aoYFbstk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets split the dataset into train and test"
      ],
      "metadata": {
        "id": "vJ8Y-bwetfy0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)"
      ],
      "metadata": {
        "id": "jSk2pXpBsSwr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "7npAKCmXt_Wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "WCKeQo-quV4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We need to preprocess the data, apply scaling (we'll use standard scaler) followed by linear regression, since the runs that we need to predict is a continuous value and the target variable might depend on the weighted average of features like no. of matches, strike rate, etc (By domain knowledge ðŸ˜…)"
      ],
      "metadata": {
        "id": "OJaBFqnduX-j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We'll make use of pipeline"
      ],
      "metadata": {
        "id": "t9N097kLvA-E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "metadata": {
        "id": "HHT2La-Su_OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = Pipeline(\n",
        "    [('scaler', StandardScaler()), \n",
        "     ('lr', LinearRegression())]\n",
        ")"
      ],
      "metadata": {
        "id": "s2Yl8k4PvRua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.fit(X_train,y_train)"
      ],
      "metadata": {
        "id": "U9ns33Hmvebp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.score(X_test,y_test)"
      ],
      "metadata": {
        "id": "iPql63fMvh1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.score(X_train,y_train)"
      ],
      "metadata": {
        "id": "kBdYMIyJy9e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## We got 99 % accuracy on test data as well as train data, therefore bias and variance both are low, which is good."
      ],
      "metadata": {
        "id": "0sjDjpYLyUrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lets check on random data(our own assumption) - imaginary batsman"
      ],
      "metadata": {
        "id": "yjx4eL_pzP2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "id": "dxktWejOzaUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mat = 16\n",
        "inns = 16\n",
        "no = 6\n",
        "hs = 90\n",
        "avg = 30\n",
        "bf = 150\n",
        "sr = 150\n",
        "h=0\n",
        "f=1\n",
        "four=20\n",
        "six=10"
      ],
      "metadata": {
        "id": "Z3XiX_tBzeCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe.predict([[mat,inns,no,hs,avg,bf,sr,h,f,four,six]])[0][0]"
      ],
      "metadata": {
        "id": "8tJzPyaY0mm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Our temproary player scored 215 runs in this season according to our model"
      ],
      "metadata": {
        "id": "uczau57S0xwr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r46SXRQ92MwI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}